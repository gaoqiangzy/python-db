<!DOCTYPE html>
<meta name='viewport' content='width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0'>
<!-- three.js library -->
<script src='vendor/three.js/build/three.js'></script>
<script src='vendor/three.js/examples/js/libs/stats.min.js'></script>
<!-- jsartookit -->
<script src='../vendor/jsartoolkit5/build/artoolkit.min.js'></script>
<script src='../vendor/jsartoolkit5/js/artoolkit.api.js'></script>
<!-- include threex.artoolkit -->
<script src='../src/threex/threex-artoolkitsource.js'></script>
<script src='../src/threex/threex-artoolkitcontext.js'></script>
<script src='../src/threex/threex-artoolkitprofile.js'></script>
<script src='../src/threex/threex-arbasecontrols.js'></script>
<script src='../src/threex/threex-armarkercontrols.js'></script>
<script src='../src/threex/threex-arsmoothedcontrols.js'></script>
<script>THREEx.ArToolkitContext.baseURL = '../'</script>

<body style='margin : 0px; overflow: hidden; font-family: Monospace;'><div style='position: absolute; top: 10px; width:100%; text-align: center;z-index:1';>
	<a href='https://github.com/jeromeetienne/AR.js/' target='_blank'>AR.js</a> - developement playground
	<br/>
	Contact me any time at <a href='https://twitter.com/jerome_etienne' target='_blank'>@jerome_etienne</a>
</div><script>
	//////////////////////////////////////////////////////////////////////////////////
	// 判断Android还是IOS
var u = navigator.userAgent;
var isAndroid = u.indexOf('Android') > -1 || u.indexOf('Adr') > -1;
var isiOS = !!u.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/);

// 摄像头调起失败
var onError = function(error){
    alert('Webcam Error\nName: '+error.name + '\nMessage: '+error.message);
}
// 摄像头调起成功
var onSuccess = function(stream){
    var video = document.createElement('video');
    video.style.width = document.documentElement.clientWidth + 'px';
    video.style.height = document.documentElement.clientHeight + 'px';

    video.srcObject = stream;

    // to start the video, when it is possible to start it only on userevent. like in android
    video.body.addEventListener('click', function(){
        video.play();
    });

    // wait until the video stream is ready
    var interval = setInterval(function(){
        if(!video.videoWidth){
            return;
        }
        document.body.appendChild(video);

        clearInterval(interval);
    }, 1000/50);
}

// check API is available
if(navigator.mediaDevices === undefined || navigator.mediaDevices.enumerateDevices === undefined || navigator.mediaDevices.getUserMedia === undefined){
    if( navigator.mediaDevices === undefined ){
        var fctName = 'navigator.mediaDevices';
    }
    else if( navigator.mediaDevices.enumerateDevices === undefined ){
        var fctName = 'navigator.mediaDevices.enumerateDevices';
    }
    else if( navigator.mediaDevices.getUserMedia === undefined ){
        var fctName = 'navigator.mediaDevices.getUserMedia';
    }
    else{
        console.assert(false);
    }
    onError({
        name: '',
        message: 'WebRTC issue-! '+fctName+' not present in your browser'
    })
}

// get available devices
navigator.mediaDevices.enumerateDevices().then(function(devices){
    // 如果是水果机
    if(isiOS){
        navigator.mediaDevices.getUserMedia({
            audio: false,
            video: {
                facingMode: 'environment'
            }
        }).then(onSuccess).catch(onError);
    }
    // 如果是安卓机
    else{
        var videoSourceId;
        var exArray = [];
        for(var i = 0; i < devices.length; i++){
            var deviceInfo = devices[i];
            // 判断是否是相机设备
            if(deviceInfo.kind == "videoinput"){
                exArray.push(deviceInfo.deviceId);
                // 判断是否是后置摄像头
                if(deviceInfo.label.split(', ')[1] == "facing back") {
                    videoSourceId = deviceInfo.deviceId;
                }
            }
        }
        // deviceInfo.label为空
        if (!videoSourceId) {
            switch (exArray.length) {
                // 单摄像头
                case 1:
                    videoSourceId = exArray[0];
                    break;
                // 多摄像头
                case 2:
                    videoSourceId = exArray[1];
                    break;
                default:
                    break;
            }
        }
        navigator.mediaDevices.getUserMedia({
            audio: false,
            video: {
                optional: [{sourceId: videoSourceId}]
            }
        }).then(onSuccess).catch(onError);
    }
}).catch(onError);
	//////////////////////////////////////////////////////////////////////////////////

	// init renderer
	var renderer	= new THREE.WebGLRenderer({
		// antialias	: true,
		alpha: true
	});
	renderer.setClearColor(new THREE.Color('lightgrey'), 0)
	// renderer.setPixelRatio( 2 );
	renderer.setSize( window.innerWidth, window.innerHeight );
	renderer.domElement.style.position = 'absolute'
	renderer.domElement.style.top = '0px'
	renderer.domElement.style.left = '0px'
	document.body.appendChild( renderer.domElement );

	// array of functions for the rendering loop
	var onRenderFcts= [];

	// init scene and camera
	var scene	= new THREE.Scene();

	var ambient = new THREE.AmbientLight( 0x666666 );
	scene.add( ambient );

	var directionalLight = new THREE.DirectionalLight( 0x887766 );
	directionalLight.position.set( -1, 1, 1 ).normalize();
	scene.add( directionalLight );
	
	//////////////////////////////////////////////////////////////////////////////////
	//		Initialize a basic camera
	//////////////////////////////////////////////////////////////////////////////////

	// Create a camera
	var camera = new THREE.Camera();
	scene.add(camera);

	////////////////////////////////////////////////////////////////////////////////
	//          handle arToolkitSource
	////////////////////////////////////////////////////////////////////////////////

	var arToolkitSource = new THREEx.ArToolkitSource({
		// to read from the webcam 
		sourceType : 'webcam',

		// // to read from an image
		// sourceType : 'image',
		// sourceUrl : THREEx.ArToolkitContext.baseURL + '../data/images/img.jpg',		
		// sourceUrl : THREEx.ArToolkitContext.baseURL + '../data/images/armchair.jpg',		

		// to read from a video
		// sourceType : 'video',
		// sourceUrl : THREEx.ArToolkitContext.baseURL + '../data/videos/headtracking.mp4',		
	})

	arToolkitSource.init(function onReady(){
		onResize()
	})
	
	// handle resize
	window.addEventListener('resize', function(){
		onResize()
	})
	function onResize(){
		arToolkitSource.onResizeElement()	
		arToolkitSource.copyElementSizeTo(renderer.domElement)	
		if( arToolkitContext.arController !== null ){
			arToolkitSource.copyElementSizeTo(arToolkitContext.arController.canvas)	
		}	
	}

	////////////////////////////////////////////////////////////////////////////////
	//          initialize arToolkitContext
	////////////////////////////////////////////////////////////////////////////////	

	// create atToolkitContext
	var arToolkitContext = new THREEx.ArToolkitContext({
		cameraParametersUrl: THREEx.ArToolkitContext.baseURL + '../data/data/camera_para.dat',
		// debug: true,
		// detectionMode: 'mono_and_matrix',
		detectionMode: 'mono',
		// detectionMode: 'color_and_matrix',
		// matrixCodeType: '3x3',

		canvasWidth: 80*3,
		canvasHeight: 60*3,

		maxDetectionRate: 30,
	})
	// initialize it
	arToolkitContext.init(function onCompleted(){
		// copy projection matrix to camera
		camera.projectionMatrix.copy( arToolkitContext.getProjectionMatrix() );
	})

	// update artoolkit on every frame
	onRenderFcts.push(function(){
		if( arToolkitSource.ready === false )	return

		arToolkitContext.update( arToolkitSource.domElement )
	})

	
	////////////////////////////////////////////////////////////////////////////////
	//          Create a ArMarkerControls
	////////////////////////////////////////////////////////////////////////////////
	
	var markerRoot = new THREE.Group
	scene.add(markerRoot)
	var markerControls = new THREEx.ArMarkerControls(arToolkitContext, markerRoot, {
		// type: 'barcode',
		// barcodeValue: 5,
		
		type : 'pattern',
		patternUrl : THREEx.ArToolkitContext.baseURL + 'examples/marker-training/examples/pattern-files/pattern-hiro.patt',
	})


	// build a smoothedControls
	var smoothedRoot = new THREE.Group()
	scene.add(smoothedRoot)
	var smoothedControls = new THREEx.ArSmoothedControls(smoothedRoot, {
		lerpPosition: 0.4,
		lerpQuaternion: 0.3,
		lerpScale: 1,
		// minVisibleDelay: 1,
		// minUnvisibleDelay: 1,
	})
	onRenderFcts.push(function(delta){
		smoothedControls.update(markerRoot)
	})	
	
	// smoothedControls.addEventListener('becameVisible', function(){
	// 	console.log('becameVisible event notified')
	// })
	// smoothedControls.addEventListener('becameUnVisible', function(){
	// 	console.log('becameUnVisible event notified')
	// })

	//////////////////////////////////////////////////////////////////////////////////
	//		add an object in the scene
	//////////////////////////////////////////////////////////////////////////////////

	// var arWorldRoot = markerRoot
	var arWorldRoot = smoothedRoot

	var mesh = new THREE.AxisHelper()
	// markerRoot.add(mesh)
	arWorldRoot.add(mesh)

	// add a torus knot
	var geometry	= new THREE.CubeGeometry(1,1,1);
	var material	= new THREE.MeshNormalMaterial({
		transparent : true,
		opacity: 0.5,
		side: THREE.DoubleSide
	})
	var mesh	= new THREE.Mesh( geometry, material );
	mesh.position.y	= geometry.parameters.height/2
	// markerRoot.add( mesh );
	arWorldRoot.add(mesh)
	
	var geometry	= new THREE.TorusKnotGeometry(0.3,0.1,64,16);
	var material	= new THREE.MeshNormalMaterial(); 
	var mesh	= new THREE.Mesh( geometry, material );
	mesh.position.y	= 0.5
	// markerRoot.add( mesh );
	arWorldRoot.add( mesh );
	
	onRenderFcts.push(function(delta){
		mesh.rotation.x += delta * Math.PI
	})

	//////////////////////////////////////////////////////////////////////////////////
	//		render the whole thing on the page
	//////////////////////////////////////////////////////////////////////////////////
	var stats = new Stats();
	document.body.appendChild( stats.dom );
	// render the scene
	onRenderFcts.push(function(){
		renderer.render( scene, camera );
		stats.update();
	})

	// run the rendering loop
	var lastTimeMsec= null
	requestAnimationFrame(function animate(nowMsec){
		// keep looping
		requestAnimationFrame( animate );
		// measure time
		lastTimeMsec	= lastTimeMsec || nowMsec-1000/60
		var deltaMsec	= Math.min(200, nowMsec - lastTimeMsec)
		lastTimeMsec	= nowMsec
		// call each update function
		onRenderFcts.forEach(function(onRenderFct){
			onRenderFct(deltaMsec/1000, nowMsec/1000)
		})
	})
</script></body>
